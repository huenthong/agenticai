{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOouA53y8WGfgJgltJ090Dj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huenthong/agenticai/blob/main/HTAgenticAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpVkMuzqbQGp",
        "outputId": "df12e7b6-e3ea-42d9-9ae5-5bff0f0c145b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.46.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.173.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.44.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pandas openai sentence-transformers faiss-cpu PyPDF2 python-docx pyngrok google-generativeai numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "import tempfile\n",
        "from typing import List, Dict, Any\n",
        "import json\n",
        "\n",
        "# For RAG implementation\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    import faiss\n",
        "    import numpy as np\n",
        "    HAS_SENTENCE_TRANSFORMERS = True\n",
        "except ImportError:\n",
        "    HAS_SENTENCE_TRANSFORMERS = False\n",
        "\n",
        "# For document processing\n",
        "try:\n",
        "    import PyPDF2\n",
        "    import docx\n",
        "    HAS_DOC_PROCESSORS = True\n",
        "except ImportError:\n",
        "    HAS_DOC_PROCESSORS = False\n",
        "\n",
        "# For Gemini API\n",
        "try:\n",
        "    import google.generativeai as genai\n",
        "    HAS_GEMINI = True\n",
        "except ImportError:\n",
        "    HAS_GEMINI = False\n",
        "\n",
        "# Database setup\n",
        "DB_PATH = 'database.db'\n",
        "\n",
        "# Initialize the database schema\n",
        "SCHEMA_SQL = '''\n",
        "PRAGMA foreign_keys = ON;\n",
        "\n",
        "DROP TABLE IF EXISTS ticket_conversations;\n",
        "DROP TABLE IF EXISTS ticket_comments;\n",
        "DROP TABLE IF EXISTS maintenance_tickets;\n",
        "DROP TABLE IF EXISTS complaint_tickets;\n",
        "DROP TABLE IF EXISTS billing_tickets;\n",
        "DROP TABLE IF EXISTS service_tickets;\n",
        "DROP TABLE IF EXISTS payments;\n",
        "DROP TABLE IF EXISTS leases;\n",
        "DROP TABLE IF EXISTS units;\n",
        "DROP TABLE IF EXISTS agents;\n",
        "DROP TABLE IF EXISTS properties;\n",
        "DROP TABLE IF EXISTS tenants;\n",
        "\n",
        "CREATE TABLE tenants (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    first_name      TEXT    NOT NULL,\n",
        "    last_name       TEXT    NOT NULL,\n",
        "    email           TEXT    UNIQUE NOT NULL,\n",
        "    phone           TEXT,\n",
        "    date_of_birth   TEXT,\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE properties (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    name            TEXT    NOT NULL,\n",
        "    address_line1   TEXT    NOT NULL,\n",
        "    address_line2   TEXT,\n",
        "    city            TEXT    NOT NULL,\n",
        "    state           TEXT,\n",
        "    postal_code     TEXT,\n",
        "    country         TEXT    NOT NULL,\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE units (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    property_id     INTEGER NOT NULL REFERENCES properties(id) ON DELETE CASCADE,\n",
        "    unit_number     TEXT    NOT NULL,\n",
        "    floor           TEXT,\n",
        "    bedrooms        INTEGER,\n",
        "    bathrooms       REAL,\n",
        "    square_feet     INTEGER,\n",
        "    status          TEXT    DEFAULT 'available',\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE leases (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    tenant_id       INTEGER NOT NULL REFERENCES tenants(id) ON DELETE CASCADE,\n",
        "    unit_id         INTEGER NOT NULL REFERENCES units(id) ON DELETE CASCADE,\n",
        "    start_date      DATETIME NOT NULL,\n",
        "    end_date        DATETIME NOT NULL,\n",
        "    rent_amount     REAL    NOT NULL,\n",
        "    security_deposit REAL,\n",
        "    status          TEXT    DEFAULT 'active',\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE agents (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    first_name      TEXT,\n",
        "    last_name       TEXT,\n",
        "    role            TEXT,\n",
        "    email           TEXT    UNIQUE,\n",
        "    phone           TEXT,\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE service_tickets (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    lease_id        INTEGER NOT NULL REFERENCES leases(id) ON DELETE CASCADE,\n",
        "    raised_by       INTEGER        REFERENCES tenants(id) ON DELETE SET NULL,\n",
        "    assigned_to     INTEGER        REFERENCES agents(id) ON DELETE SET NULL,\n",
        "    category        TEXT     NOT NULL,\n",
        "    description     TEXT     NOT NULL,\n",
        "    status          TEXT     DEFAULT 'open',\n",
        "    priority        TEXT     DEFAULT 'normal',\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    updated_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE maintenance_tickets (\n",
        "    ticket_id       INTEGER PRIMARY KEY REFERENCES service_tickets(id) ON DELETE CASCADE,\n",
        "    subcategory     TEXT,\n",
        "    scheduled_for   DATETIME,\n",
        "    technician_id   INTEGER REFERENCES agents(id) ON DELETE SET NULL\n",
        ");\n",
        "\n",
        "CREATE TABLE complaint_tickets (\n",
        "    ticket_id       INTEGER PRIMARY KEY REFERENCES service_tickets(id) ON DELETE CASCADE,\n",
        "    severity        TEXT    NOT NULL,\n",
        "    complaint_type  TEXT,\n",
        "    resolved_on     DATETIME\n",
        ");\n",
        "\n",
        "CREATE TABLE billing_tickets (\n",
        "    ticket_id       INTEGER PRIMARY KEY REFERENCES service_tickets(id) ON DELETE CASCADE,\n",
        "    invoice_number  TEXT    NOT NULL,\n",
        "    amount_disputed REAL,\n",
        "    resolution_date DATETIME\n",
        ");\n",
        "\n",
        "CREATE TABLE ticket_comments (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    ticket_id       INTEGER NOT NULL REFERENCES service_tickets(id) ON DELETE CASCADE,\n",
        "    author_id       INTEGER NOT NULL,\n",
        "    author_type     TEXT    NOT NULL,\n",
        "    comment_text    TEXT    NOT NULL,\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE ticket_conversations (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    ticket_id       INTEGER NOT NULL REFERENCES service_tickets(id) ON DELETE CASCADE,\n",
        "    author_type     TEXT    NOT NULL,\n",
        "    author_id       INTEGER NOT NULL,\n",
        "    message_text    TEXT    NOT NULL,\n",
        "    sent_at         DATETIME NOT NULL DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE payments (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    lease_id        INTEGER NOT NULL REFERENCES leases(id) ON DELETE CASCADE,\n",
        "    payment_type    TEXT    NOT NULL,\n",
        "    billing_period  TEXT,\n",
        "    due_date        DATETIME,\n",
        "    amount          REAL    NOT NULL,\n",
        "    method          TEXT,\n",
        "    paid_on         DATETIME,\n",
        "    reference_number TEXT,\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "'''\n",
        "\n",
        "class DatabaseManager:\n",
        "    def __init__(self, db_path: str):\n",
        "        self.db_path = db_path\n",
        "        self.init_database()\n",
        "\n",
        "    def init_database(self):\n",
        "        \"\"\"Initialize database with schema\"\"\"\n",
        "        with sqlite3.connect(self.db_path) as conn:\n",
        "            conn.executescript(SCHEMA_SQL)\n",
        "\n",
        "    def get_connection(self):\n",
        "        return sqlite3.connect(self.db_path)\n",
        "\n",
        "    def execute_query(self, query: str, params: tuple = None):\n",
        "        \"\"\"Execute a query and return results\"\"\"\n",
        "        try:\n",
        "            with self.get_connection() as conn:\n",
        "                if params:\n",
        "                    df = pd.read_sql_query(query, conn, params=params)\n",
        "                else:\n",
        "                    df = pd.read_sql_query(query, conn)\n",
        "                return df\n",
        "        except Exception as e:\n",
        "            st.error(f\"Database error: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def get_table_info(self):\n",
        "        \"\"\"Get information about all tables\"\"\"\n",
        "        query = \"\"\"\n",
        "        SELECT name FROM sqlite_master\n",
        "        WHERE type='table' AND name NOT LIKE 'sqlite_%'\n",
        "        ORDER BY name\n",
        "        \"\"\"\n",
        "        return self.execute_query(query)\n",
        "\n",
        "    def get_table_schema(self, table_name: str):\n",
        "        \"\"\"Get schema for a specific table\"\"\"\n",
        "        query = f\"PRAGMA table_info({table_name})\"\n",
        "        return self.execute_query(query)\n",
        "\n",
        "class DocumentProcessor:\n",
        "    @staticmethod\n",
        "    def extract_text_from_pdf(file):\n",
        "        \"\"\"Extract text from PDF file\"\"\"\n",
        "        if not HAS_DOC_PROCESSORS:\n",
        "            return \"PDF processing not available. Install PyPDF2.\"\n",
        "\n",
        "        try:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            return f\"Error processing PDF: {str(e)}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_text_from_docx(file):\n",
        "        \"\"\"Extract text from DOCX file\"\"\"\n",
        "        if not HAS_DOC_PROCESSORS:\n",
        "            return \"DOCX processing not available. Install python-docx.\"\n",
        "\n",
        "        try:\n",
        "            doc = docx.Document(file)\n",
        "            text = \"\"\n",
        "            for paragraph in doc.paragraphs:\n",
        "                text += paragraph.text + \"\\n\"\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            return f\"Error processing DOCX: {str(e)}\"\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_text_from_txt(file):\n",
        "        \"\"\"Extract text from TXT file\"\"\"\n",
        "        try:\n",
        "            return file.read().decode('utf-8')\n",
        "        except Exception as e:\n",
        "            return f\"Error processing TXT: {str(e)}\"\n",
        "\n",
        "class RAGSystem:\n",
        "    def __init__(self):\n",
        "        self.embeddings_model = None\n",
        "        self.index = None\n",
        "        self.documents = []\n",
        "        self.document_embeddings = []\n",
        "\n",
        "    def initialize_embeddings(self):\n",
        "        \"\"\"Initialize the embeddings model\"\"\"\n",
        "        if not HAS_SENTENCE_TRANSFORMERS:\n",
        "            st.error(\"Sentence Transformers not available. Install sentence-transformers for RAG functionality.\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            self.embeddings_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error initializing embeddings model: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def add_documents(self, documents: List[str]):\n",
        "        \"\"\"Add documents to the RAG system\"\"\"\n",
        "        if not self.embeddings_model:\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            # Split documents into chunks\n",
        "            chunks = []\n",
        "            for doc in documents:\n",
        "                doc_chunks = self._split_text(doc)\n",
        "                chunks.extend(doc_chunks)\n",
        "\n",
        "            # Generate embeddings\n",
        "            embeddings = self.embeddings_model.encode(chunks)\n",
        "\n",
        "            # Create or update FAISS index\n",
        "            if self.index is None:\n",
        "                self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "\n",
        "            self.index.add(embeddings.astype(np.float32))\n",
        "            self.documents.extend(chunks)\n",
        "            self.document_embeddings.extend(embeddings)\n",
        "\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error adding documents: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _split_text(self, text: str, chunk_size: int = 500, overlap: int = 50):\n",
        "        \"\"\"Split text into chunks\"\"\"\n",
        "        chunks = []\n",
        "        start = 0\n",
        "        while start < len(text):\n",
        "            end = min(start + chunk_size, len(text))\n",
        "            chunks.append(text[start:end])\n",
        "            start = end - overlap\n",
        "            if start >= len(text):\n",
        "                break\n",
        "        return chunks\n",
        "\n",
        "    def retrieve_relevant_docs(self, query: str, k: int = 3):\n",
        "        \"\"\"Retrieve relevant documents for a query\"\"\"\n",
        "        if not self.embeddings_model or not self.index:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            query_embedding = self.embeddings_model.encode([query])\n",
        "            distances, indices = self.index.search(query_embedding.astype(np.float32), k)\n",
        "\n",
        "            relevant_docs = []\n",
        "            for idx in indices[0]:\n",
        "                if idx < len(self.documents):\n",
        "                    relevant_docs.append(self.documents[idx])\n",
        "\n",
        "            return relevant_docs\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error retrieving documents: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "class ChatBot:\n",
        "    def __init__(self, db_manager: DatabaseManager, rag_system: RAGSystem):\n",
        "        self.db_manager = db_manager\n",
        "        self.rag_system = rag_system\n",
        "        self.gemini_model = None\n",
        "\n",
        "    def set_gemini_api_key(self, api_key: str):\n",
        "        \"\"\"Set Gemini API key\"\"\"\n",
        "        if not HAS_GEMINI:\n",
        "            st.error(\"Google GenerativeAI library not available. Install google-generativeai package.\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            genai.configure(api_key=api_key)\n",
        "            self.gemini_model = genai.GenerativeModel('gemini-pro')\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error setting Gemini API key: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def generate_sql_query(self, user_question: str) -> str:\n",
        "        \"\"\"Generate SQL query based on user question\"\"\"\n",
        "        schema_info = self._get_database_schema()\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are a SQL expert. Based on the following database schema and user question,\n",
        "        generate a SQL query that would answer the question.\n",
        "\n",
        "        Database Schema:\n",
        "        {schema_info}\n",
        "\n",
        "        User Question: {user_question}\n",
        "\n",
        "        Please provide only the SQL query without any explanation. Make sure the SQL is valid SQLite syntax.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.gemini_model:\n",
        "            try:\n",
        "                response = self.gemini_model.generate_content(prompt)\n",
        "                sql_query = response.text.strip()\n",
        "\n",
        "                # Clean up the response to extract only SQL\n",
        "                if \"```sql\" in sql_query:\n",
        "                    sql_query = sql_query.split(\"```sql\")[1].split(\"```\")[0].strip()\n",
        "                elif \"```\" in sql_query:\n",
        "                    sql_query = sql_query.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "                return sql_query\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error generating SQL query with Gemini: {str(e)}\")\n",
        "                return self._generate_simple_query(user_question)\n",
        "        else:\n",
        "            # Fallback to simple query generation\n",
        "            return self._generate_simple_query(user_question)\n",
        "\n",
        "    def _get_database_schema(self) -> str:\n",
        "        \"\"\"Get database schema information\"\"\"\n",
        "        tables = self.db_manager.get_table_info()\n",
        "        schema_info = \"Database Tables:\\n\"\n",
        "\n",
        "        if tables is not None:\n",
        "            for _, row in tables.iterrows():\n",
        "                table_name = row['name']\n",
        "                schema_info += f\"\\nTable: {table_name}\\n\"\n",
        "                table_schema = self.db_manager.get_table_schema(table_name)\n",
        "                if table_schema is not None:\n",
        "                    for _, col in table_schema.iterrows():\n",
        "                        schema_info += f\"  - {col['name']} ({col['type']})\\n\"\n",
        "\n",
        "        return schema_info\n",
        "\n",
        "    def _generate_simple_query(self, question: str) -> str:\n",
        "        \"\"\"Generate simple SQL queries based on keywords\"\"\"\n",
        "        question_lower = question.lower()\n",
        "\n",
        "        if \"tenant\" in question_lower:\n",
        "            return \"SELECT * FROM tenants LIMIT 10\"\n",
        "        elif \"property\" in question_lower or \"properties\" in question_lower:\n",
        "            return \"SELECT * FROM properties LIMIT 10\"\n",
        "        elif \"lease\" in question_lower:\n",
        "            return \"SELECT * FROM leases LIMIT 10\"\n",
        "        elif \"ticket\" in question_lower:\n",
        "            return \"SELECT * FROM service_tickets LIMIT 10\"\n",
        "        elif \"payment\" in question_lower:\n",
        "            return \"SELECT * FROM payments LIMIT 10\"\n",
        "        else:\n",
        "            return \"SELECT name FROM sqlite_master WHERE type='table'\"\n",
        "\n",
        "    def answer_question(self, question: str) -> str:\n",
        "        \"\"\"Answer user question using RAG and database query\"\"\"\n",
        "        response = f\"**Question:** {question}\\n\\n\"\n",
        "\n",
        "        # Try to get relevant documents from RAG\n",
        "        relevant_docs = self.rag_system.retrieve_relevant_docs(question)\n",
        "\n",
        "        # Try to generate and execute SQL query\n",
        "        sql_query = self.generate_sql_query(question)\n",
        "\n",
        "        if sql_query:\n",
        "            response += f\"**Generated SQL Query:**\\n```sql\\n{sql_query}\\n```\\n\\n\"\n",
        "\n",
        "            # Execute the query\n",
        "            df = self.db_manager.execute_query(sql_query)\n",
        "            if df is not None and not df.empty:\n",
        "                response += f\"**Database Results:**\\n\"\n",
        "                response += df.to_string(index=False)\n",
        "                response += \"\\n\\n\"\n",
        "            else:\n",
        "                response += \"**Database Results:** No data found or query error.\\n\\n\"\n",
        "\n",
        "        # Add relevant documents if available\n",
        "        if relevant_docs:\n",
        "            response += f\"**Relevant Documents:**\\n\"\n",
        "            for i, doc in enumerate(relevant_docs[:2], 1):\n",
        "                response += f\"{i}. {doc[:200]}...\\n\\n\"\n",
        "\n",
        "        # Generate AI response if Gemini is available\n",
        "        if self.gemini_model:\n",
        "            context = f\"Database query result: {df.to_string() if df is not None else 'No results'}\\n\"\n",
        "            context += f\"Relevant documents: {' '.join(relevant_docs[:2])}\\n\"\n",
        "\n",
        "            ai_prompt = f\"\"\"\n",
        "            You are a helpful assistant for a property management system. Based on the following context,\n",
        "            provide a clear, concise, and helpful answer to the user's question.\n",
        "\n",
        "            Question: {question}\n",
        "\n",
        "            Context:\n",
        "            {context}\n",
        "\n",
        "            Please provide a comprehensive answer that interprets the data and gives practical insights.\n",
        "            Focus on being helpful and actionable in your response.\n",
        "            \"\"\"\n",
        "\n",
        "            try:\n",
        "                ai_response = self.gemini_model.generate_content(ai_prompt)\n",
        "                response += f\"**AI Response:**\\n{ai_response.text}\"\n",
        "            except Exception as e:\n",
        "                response += f\"**AI Response Error:** {str(e)}\"\n",
        "\n",
        "        return response\n",
        "\n",
        "# Streamlit App\n",
        "def main():\n",
        "    st.set_page_config(\n",
        "        page_title=\"Property Management RAG Chatbot\",\n",
        "        page_icon=\"üè†\",\n",
        "        layout=\"wide\"\n",
        "    )\n",
        "\n",
        "    st.title(\"üè† Property Management RAG Chatbot\")\n",
        "    st.markdown(\"Ask questions about your property management data and upload documents for enhanced context.\")\n",
        "\n",
        "    # Initialize session state\n",
        "    if 'db_manager' not in st.session_state:\n",
        "        st.session_state.db_manager = DatabaseManager(DB_PATH)\n",
        "\n",
        "    if 'rag_system' not in st.session_state:\n",
        "        st.session_state.rag_system = RAGSystem()\n",
        "\n",
        "    if 'chatbot' not in st.session_state:\n",
        "        st.session_state.chatbot = ChatBot(st.session_state.db_manager, st.session_state.rag_system)\n",
        "\n",
        "    if 'chat_history' not in st.session_state:\n",
        "        st.session_state.chat_history = []\n",
        "\n",
        "    if 'gemini_configured' not in st.session_state:\n",
        "        st.session_state.gemini_configured = False\n",
        "\n",
        "    # Sidebar for configuration\n",
        "    with st.sidebar:\n",
        "        st.header(\"‚öôÔ∏è Configuration\")\n",
        "\n",
        "        # Gemini API Key\n",
        "        st.subheader(\"üîë Gemini API Key\")\n",
        "        if not HAS_GEMINI:\n",
        "            st.error(\"Please install google-generativeai: `pip install google-generativeai`\")\n",
        "        else:\n",
        "            api_key = st.text_input(\"Enter your Gemini API Key\", type=\"password\")\n",
        "            if st.button(\"Set API Key\"):\n",
        "                if api_key:\n",
        "                    if st.session_state.chatbot.set_gemini_api_key(api_key):\n",
        "                        st.session_state.gemini_configured = True\n",
        "                        st.success(\"Gemini API Key configured successfully!\")\n",
        "                    else:\n",
        "                        st.error(\"Failed to configure API Key\")\n",
        "                else:\n",
        "                    st.error(\"Please enter an API Key\")\n",
        "\n",
        "            if st.session_state.gemini_configured:\n",
        "                st.success(\"‚úÖ Gemini API configured\")\n",
        "\n",
        "        # Document Upload\n",
        "        st.subheader(\"üìÑ Document Upload\")\n",
        "        if not HAS_SENTENCE_TRANSFORMERS:\n",
        "            st.error(\"Please install sentence-transformers: `pip install sentence-transformers`\")\n",
        "\n",
        "        uploaded_files = st.file_uploader(\n",
        "            \"Upload documents (PDF, DOCX, TXT)\",\n",
        "            type=['pdf', 'docx', 'txt'],\n",
        "            accept_multiple_files=True,\n",
        "            help=\"Upload relevant documents to enhance the chatbot's knowledge base\"\n",
        "        )\n",
        "\n",
        "        if uploaded_files:\n",
        "            if st.button(\"Process Documents\"):\n",
        "                if not st.session_state.rag_system.embeddings_model:\n",
        "                    if st.session_state.rag_system.initialize_embeddings():\n",
        "                        st.success(\"Embeddings model initialized!\")\n",
        "                    else:\n",
        "                        st.error(\"Failed to initialize embeddings model\")\n",
        "                        st.stop()\n",
        "\n",
        "                documents = []\n",
        "                for file in uploaded_files:\n",
        "                    if file.type == \"application/pdf\":\n",
        "                        text = DocumentProcessor.extract_text_from_pdf(file)\n",
        "                    elif file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
        "                        text = DocumentProcessor.extract_text_from_docx(file)\n",
        "                    elif file.type == \"text/plain\":\n",
        "                        text = DocumentProcessor.extract_text_from_txt(file)\n",
        "                    else:\n",
        "                        continue\n",
        "\n",
        "                    documents.append(text)\n",
        "\n",
        "                if documents:\n",
        "                    if st.session_state.rag_system.add_documents(documents):\n",
        "                        st.success(f\"Successfully processed {len(documents)} documents!\")\n",
        "                    else:\n",
        "                        st.error(\"Failed to process documents\")\n",
        "\n",
        "        # Database Info\n",
        "        st.subheader(\"üóÑÔ∏è Database Info\")\n",
        "        if st.button(\"Show Tables\"):\n",
        "            tables = st.session_state.db_manager.get_table_info()\n",
        "            if tables is not None:\n",
        "                st.dataframe(tables)\n",
        "\n",
        "        # Sample Data\n",
        "        st.subheader(\"üìù Sample Data\")\n",
        "        if st.button(\"Insert Sample Data\"):\n",
        "            insert_sample_data()\n",
        "            st.success(\"Sample data inserted!\")\n",
        "\n",
        "        # Installation Instructions\n",
        "        st.subheader(\"üì¶ Installation\")\n",
        "        with st.expander(\"Required Packages\"):\n",
        "            st.code(\"\"\"\n",
        "pip install streamlit\n",
        "pip install google-generativeai\n",
        "pip install sentence-transformers\n",
        "pip install faiss-cpu\n",
        "pip install PyPDF2\n",
        "pip install python-docx\n",
        "pip install pandas\n",
        "pip install numpy\n",
        "            \"\"\")\n",
        "\n",
        "    # Main chat interface\n",
        "    st.header(\"üí¨ Chat Interface\")\n",
        "\n",
        "    # Instructions\n",
        "    if not st.session_state.gemini_configured:\n",
        "        st.info(\"üëÜ Please configure your Gemini API key in the sidebar to enable AI responses.\")\n",
        "\n",
        "    # Display chat history\n",
        "    for message in st.session_state.chat_history:\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "    # Chat input\n",
        "    if prompt := st.chat_input(\"Ask me anything about your property management data...\"):\n",
        "        # Add user message to chat history\n",
        "        st.session_state.chat_history.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "        # Display user message\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "        # Generate and display assistant response\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            with st.spinner(\"Thinking...\"):\n",
        "                response = st.session_state.chatbot.answer_question(prompt)\n",
        "                st.markdown(response)\n",
        "\n",
        "        # Add assistant response to chat history\n",
        "        st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "    # Clear chat history button\n",
        "    if st.button(\"üóëÔ∏è Clear Chat History\"):\n",
        "        st.session_state.chat_history = []\n",
        "        st.rerun()\n",
        "\n",
        "def insert_sample_data():\n",
        "    \"\"\"Insert sample data into the database\"\"\"\n",
        "    with sqlite3.connect(DB_PATH) as conn:\n",
        "        c = conn.cursor()\n",
        "\n",
        "        # Sample tenants\n",
        "        tenants_data = [\n",
        "            ('John', 'Doe', 'john.doe@email.com', '+1-555-123-4567', '1990-01-15'),\n",
        "            ('Jane', 'Smith', 'jane.smith@email.com', '+1-555-234-5678', '1985-03-22'),\n",
        "            ('Bob', 'Johnson', 'bob.johnson@email.com', '+1-555-345-6789', '1992-07-08'),\n",
        "            ('Alice', 'Brown', 'alice.brown@email.com', '+1-555-456-7890', '1988-11-30'),\n",
        "            ('Charlie', 'Wilson', 'charlie.wilson@email.com', '+1-555-567-8901', '1995-05-12'),\n",
        "        ]\n",
        "\n",
        "        for tenant in tenants_data:\n",
        "            c.execute(\"INSERT OR IGNORE INTO tenants (first_name, last_name, email, phone, date_of_birth) VALUES (?, ?, ?, ?, ?)\", tenant)\n",
        "\n",
        "        # Sample properties\n",
        "        properties_data = [\n",
        "            ('Sunset Apartments', '123 Main St', 'Unit A', 'Downtown', 'CA', '90210', 'USA'),\n",
        "            ('Ocean View Complex', '456 Beach Blvd', 'Building B', 'Coastal', 'CA', '90211', 'USA'),\n",
        "            ('Mountain Ridge', '789 Hill Road', 'Tower C', 'Uptown', 'CA', '90212', 'USA'),\n",
        "        ]\n",
        "\n",
        "        for prop in properties_data:\n",
        "            c.execute(\"INSERT OR IGNORE INTO properties (name, address_line1, address_line2, city, state, postal_code, country) VALUES (?, ?, ?, ?, ?, ?, ?)\", prop)\n",
        "\n",
        "        # Sample units\n",
        "        units_data = [\n",
        "            (1, '101', '1', 2, 1.5, 850, 'occupied'),\n",
        "            (1, '102', '1', 1, 1.0, 650, 'available'),\n",
        "            (2, '201', '2', 3, 2.0, 1200, 'occupied'),\n",
        "            (2, '202', '2', 2, 2.0, 1000, 'maintenance'),\n",
        "            (3, '301', '3', 1, 1.0, 700, 'available'),\n",
        "        ]\n",
        "\n",
        "        for unit in units_data:\n",
        "            c.execute(\"INSERT OR IGNORE INTO units (property_id, unit_number, floor, bedrooms, bathrooms, square_feet, status) VALUES (?, ?, ?, ?, ?, ?, ?)\", unit)\n",
        "\n",
        "        # Sample agents\n",
        "        agents_data = [\n",
        "            ('Mike', 'Manager', 'Property Manager', 'mike.manager@company.com', '+1-555-111-2222'),\n",
        "            ('Sarah', 'Tech', 'Maintenance Technician', 'sarah.tech@company.com', '+1-555-333-4444'),\n",
        "            ('David', 'Admin', 'Administrative Assistant', 'david.admin@company.com', '+1-555-555-6666'),\n",
        "        ]\n",
        "\n",
        "        for agent in agents_data:\n",
        "            c.execute(\"INSERT OR IGNORE INTO agents (first_name, last_name, role, email, phone) VALUES (?, ?, ?, ?, ?)\", agent)\n",
        "\n",
        "        # Sample leases\n",
        "        leases_data = [\n",
        "            (1, 1, '2024-01-01', '2024-12-31', 1500.00, 1500.00, 'active'),\n",
        "            (2, 3, '2024-02-01', '2025-01-31', 2200.00, 2200.00, 'active'),\n",
        "            (3, 1, '2023-06-01', '2024-05-31', 1800.00, 1800.00, 'expired'),\n",
        "        ]\n",
        "\n",
        "        for lease in leases_data:\n",
        "            c.execute(\"INSERT OR IGNORE INTO leases (tenant_id, unit_id, start_date, end_date, rent_amount, security_deposit, status) VALUES (?, ?, ?, ?, ?, ?, ?)\", lease)\n",
        "\n",
        "        # Sample service tickets\n",
        "        tickets_data = [\n",
        "            (1, 1, 1, 'maintenance', 'Leaking faucet in kitchen', 'open', 'normal'),\n",
        "            (2, 2, 2, 'complaint', 'Noisy neighbors upstairs', 'in_progress', 'high'),\n",
        "            (1, 1, 3, 'billing', 'Question about utility charges', 'closed', 'low'),\n",
        "        ]\n",
        "\n",
        "        for ticket in tickets_data:\n",
        "            c.execute(\"INSERT OR IGNORE INTO service_tickets (lease_id, raised_by, assigned_to, category, description, status, priority) VALUES (?, ?, ?, ?, ?, ?, ?)\", ticket)\n",
        "\n",
        "        # Sample payments\n",
        "        payments_data = [\n",
        "            (1, 'rent', '2024-01', '2024-01-01', 1500.00, 'bank_transfer', '2024-01-01', 'TXN001'),\n",
        "            (2, 'rent', '2024-02', '2024-02-01', 2200.00, 'check', '2024-02-02', 'CHK001'),\n",
        "            (1, 'utilities', '2024-01', '2024-01-15', 150.00, 'credit_card', '2024-01-15', 'CC001'),\n",
        "        ]\n",
        "\n",
        "        for payment in payments_data:\n",
        "            c.execute(\"INSERT OR IGNORE INTO payments (lease_id, payment_type, billing_period, due_date, amount, method, paid_on, reference_number) VALUES (?, ?, ?, ?, ?, ?, ?, ?)\", payment)\n",
        "\n",
        "        conn.commit()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1K0mDUGnJ2S",
        "outputId": "de8cb895-baa4-43e5-88a2-1fc534e0cbdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile init_db.py\n",
        "import sqlite3\n",
        "\n",
        "# Path to your SQLite database file\n",
        "DB_PATH = 'database.db'\n",
        "\n",
        "# SQL schema as a multi-line string\n",
        "SCHEMA_SQL = '''\n",
        "PRAGMA foreign_keys = ON;\n",
        "\n",
        "DROP TABLE IF EXISTS ticket_conversations;\n",
        "DROP TABLE IF EXISTS ticket_comments;\n",
        "DROP TABLE IF EXISTS maintenance_tickets;\n",
        "DROP TABLE IF EXISTS complaint_tickets;\n",
        "DROP TABLE IF EXISTS billing_tickets;\n",
        "DROP TABLE IF EXISTS service_tickets;\n",
        "DROP TABLE IF EXISTS payments;\n",
        "DROP TABLE IF EXISTS leases;\n",
        "DROP TABLE IF EXISTS units;\n",
        "DROP TABLE IF EXISTS agents;\n",
        "DROP TABLE IF EXISTS properties;\n",
        "DROP TABLE IF EXISTS tenants;\n",
        "\n",
        "CREATE TABLE tenants (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    first_name      TEXT    NOT NULL,\n",
        "    last_name       TEXT    NOT NULL,\n",
        "    email           TEXT    UNIQUE NOT NULL,\n",
        "    phone           TEXT,\n",
        "    date_of_birth   TEXT,\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE properties (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    name            TEXT    NOT NULL,\n",
        "    address_line1   TEXT    NOT NULL,\n",
        "    address_line2   TEXT,\n",
        "    city            TEXT    NOT NULL,\n",
        "    state           TEXT,\n",
        "    postal_code     TEXT,\n",
        "    country         TEXT    NOT NULL,\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE units (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    property_id     INTEGER NOT NULL REFERENCES properties(id) ON DELETE CASCADE,\n",
        "    unit_number     TEXT    NOT NULL,\n",
        "    floor           TEXT,\n",
        "    bedrooms        INTEGER,\n",
        "    bathrooms       REAL,\n",
        "    square_feet     INTEGER,\n",
        "    status          TEXT    DEFAULT 'available',\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE leases (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    tenant_id       INTEGER NOT NULL REFERENCES tenants(id) ON DELETE CASCADE,\n",
        "    unit_id         INTEGER NOT NULL REFERENCES units(id) ON DELETE CASCADE,\n",
        "    start_date      DATETIME NOT NULL,\n",
        "    end_date        DATETIME NOT NULL,\n",
        "    rent_amount     REAL    NOT NULL,\n",
        "    security_deposit REAL,\n",
        "    status          TEXT    DEFAULT 'active',\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE agents (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    first_name      TEXT,\n",
        "    last_name       TEXT,\n",
        "    role            TEXT,\n",
        "    email           TEXT    UNIQUE,\n",
        "    phone           TEXT,\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE service_tickets (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    lease_id        INTEGER NOT NULL REFERENCES leases(id) ON DELETE CASCADE,\n",
        "    raised_by       INTEGER        REFERENCES tenants(id) ON DELETE SET NULL,\n",
        "    assigned_to     INTEGER        REFERENCES agents(id) ON DELETE SET NULL,\n",
        "    category        TEXT     NOT NULL,\n",
        "    description     TEXT     NOT NULL,\n",
        "    status          TEXT     DEFAULT 'open',\n",
        "    priority        TEXT     DEFAULT 'normal',\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    updated_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE maintenance_tickets (\n",
        "    ticket_id       INTEGER PRIMARY KEY REFERENCES service_tickets(id) ON DELETE CASCADE,\n",
        "    subcategory     TEXT,\n",
        "    scheduled_for   DATETIME,\n",
        "    technician_id   INTEGER REFERENCES agents(id) ON DELETE SET NULL\n",
        ");\n",
        "\n",
        "CREATE TABLE complaint_tickets (\n",
        "    ticket_id       INTEGER PRIMARY KEY REFERENCES service_tickets(id) ON DELETE CASCADE,\n",
        "    severity        TEXT    NOT NULL,\n",
        "    complaint_type  TEXT,\n",
        "    resolved_on     DATETIME\n",
        ");\n",
        "\n",
        "CREATE TABLE billing_tickets (\n",
        "    ticket_id       INTEGER PRIMARY KEY REFERENCES service_tickets(id) ON DELETE CASCADE,\n",
        "    invoice_number  TEXT    NOT NULL,\n",
        "    amount_disputed REAL,\n",
        "    resolution_date DATETIME\n",
        ");\n",
        "\n",
        "CREATE TABLE ticket_comments (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    ticket_id       INTEGER NOT NULL REFERENCES service_tickets(id) ON DELETE CASCADE,\n",
        "    author_id       INTEGER NOT NULL,\n",
        "    author_type     TEXT    NOT NULL,\n",
        "    comment_text    TEXT    NOT NULL,\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE ticket_conversations (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    ticket_id       INTEGER NOT NULL REFERENCES service_tickets(id) ON DELETE CASCADE,\n",
        "    author_type     TEXT    NOT NULL,\n",
        "    author_id       INTEGER NOT NULL,\n",
        "    message_text    TEXT    NOT NULL,\n",
        "    sent_at         DATETIME NOT NULL DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "\n",
        "CREATE TABLE payments (\n",
        "    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    timestamp       DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours')),\n",
        "    lease_id        INTEGER NOT NULL REFERENCES leases(id) ON DELETE CASCADE,\n",
        "    payment_type    TEXT    NOT NULL,\n",
        "    billing_period  TEXT,\n",
        "    due_date        DATETIME,\n",
        "    amount          REAL    NOT NULL,\n",
        "    method          TEXT,\n",
        "    paid_on         DATETIME,\n",
        "    reference_number TEXT,\n",
        "    created_at      DATETIME DEFAULT (strftime('%Y-%m-%d %H:%M:%S','now','+8 hours'))\n",
        ");\n",
        "'''\n",
        "\n",
        "def initialize_database():\n",
        "    with sqlite3.connect(DB_PATH) as conn:\n",
        "        conn.executescript(SCHEMA_SQL)\n",
        "    print('Database schema created successfully.')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    initialize_database()\n",
        "\n",
        "\n",
        "# Run the initialization\n",
        "exec(open('init_db.py').read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j57ghKfHovTk",
        "outputId": "aad44cd4-0da0-4f58-af04-2c2b28e947bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing init_db.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import threading\n",
        "#import subprocess\n",
        "#import time\n",
        "#from pyngrok import ngrok\n",
        "\n",
        "#def run_streamlit():\n",
        "    #subprocess.run(['streamlit', 'run', 'streamlit_app.py', '--server.port', '8501'])\n",
        "\n",
        "# Start Streamlit\n",
        "#threading.Thread(target=run_streamlit, daemon=True).start()\n",
        "#time.sleep(10)\n",
        "\n",
        "# Create public URL\n",
        "#public_url = ngrok.connect(8501)\n",
        "#print(f\"Your app is available at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "eOUjDUozpAyt",
        "outputId": "3706fb25-5efb-4aa6-ec08-fc42c9d1a4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-07-01T01:40:58+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-07-01T01:40:58+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-07-01T01:40:58+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-874983057.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Create public URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Your app is available at: {public_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Opening tunnel named: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    448\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n."
          ]
        }
      ]
    }
  ]
}